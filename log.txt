****************************************************************
22MAY04
**************************************************************** 
* Problem in cv2.VideoCapture.set(cv2.CAP_PROP_POS,frame_number)
    - According to the OpenCV Issue #9053, moving the play header to a specific frame with the
        "set" function does not guarantee the result.
    - However, until now, there was no issue when the frame was called sequentially using the
        read or grab function. 
    - So I changed all frame getting functions to sequentially call grab function until
        the play header is on the target frame, and retrieve the frame with the read function.
****************************************************************
22APR21
**************************************************************** 
* Working Model Complete
    - I changed the main net's structure. The network now merge pre-trained three layers from the 
        initial structure and use it as the base network. 
    - I also applied the early stopping (w/ retaining the best parameter) and adjustable learning. 
    - Finally performed hyperparameter tunnning using a simple grid-search method. 
    - I also included dataset from the manually selected 'failed data' resulting nearly 1000
        labeled images.
    - These dramatically improved the error rate, and the Mean Average Error(MAE) of the validation
        dataset is about 12(px).
    - Two models are currently available.
        - butterNet_V1 : Previously used net (Created on 2021OCT15).
            MAE(incl. all data) : 10.49
        - butterNet_V2 :
            MAE(incl. all data) : 5.04 
        - butterNet_V2_1 :
            MAE(incl. all data) : 4.48 
        - butterNet_V2_2 :
            MAE(incl. all data) : 5.23 (last 10% 6.58)

* /NetworkTraining/loadDataset.py dataset parsing method changed
    - load the dataset image and csv file always raised the error, 
        if the python console is in a wrong location.
        I changed this using the glob function and made it to 
        run regardless of the cwd.
        
****************************************************************
22APR11
**************************************************************** 
* Rearranging the Net to make a more accurate prediction
* Testing a net with head location detection function only.

****************************************************************
22MAR29
**************************************************************** 
* ROI detection method now use the prev location
* network uses the batch prediction
* rearranged the code

****************************************************************
22MAR21
**************************************************************** 
+ Save failed frames as dataset during relabeling
    - Use the 'G' button to save the data
+ Use location info to recognize the next blob
    - Since we use the likelihood method, we can all ways other criterion for
        selecting the most probable blob.
    - After analysing the "20JUN1-200827-171419_PL" video, these are the some parameters for
        usual moving speed.
        - FPS = 5
        - animal size (median) = 1904
        - sqrt(animal size) = 43.63
        - Gaussian peak (mean) = 14.53
        - Gaussian sd = 13.61
    - Since the Gaussian peak is roughly 0.33 of the sqrt(animalSize), 
        a Gaussian distribution of mean= 0.33*sqrt(animalSize) and sd=0.33*sqrt(animalSize) seems
        a reasonable distance distribution between 0.2 sec
* TODO 
    - [DONE] check if the network is predicting all frames until the last one

****************************************************************
22MAR16
**************************************************************** 
* New ROI extractor
    - Before, foreground objects were extracted using the backgroundSubtractorMOG2.
    - However, this blackbox algorithm fails when 
        1) animal stays in a same area for a long time, 
        2) the algorithm detect the wrong object from the beginning
    - So, I designed a new backgroundSubtractor algorithm using a simple median frames.
        This algorithm performs worse than the backgroundSubtractorMOG2, but since I started 
        to use a stronger animal contour detection algorithm, this does not cause problems.
    - New animal contour detection algorithm added. 
        Initially, the animal model is built using size, circularity, convexity. After applying the
        background subtractor algorithm, the likelihood of all contours are calculated, and the
        contour with the highest likelihood is selected as a animal.
        Right now, this contour does not care about the previous location, but adding this
        information will dramatically increase the detection accuracy.
* Batch Prediction
    - Predicting a single dataset using a CNN is extremely inefficient. I implemented batch
        prediction and this increased the speed by x3.7. 
    - However, if the size of the batch is too large, the GPU's memory runs out. An automatic bath size
        selection algorithm might help. But I'll do this later ;P
* TODO
    - [DONE] save wrong frame as dataset (ReLabeler)
    - [DONE] Location parsing

****************************************************************
21OCT15
**************************************************************** 
* New Model
    - If the wire of the recording device is in the ROI, time to time the Net fails to detect the head.
    - I added two dropout layers to the original Net, but the accuracy is not high enough.
        -7800 epochs : 15 hours : GTX 1060 3G
    - Instead, I labeled some failed images and continued the training with the original Net
+ Continue Training Function added
    - I separated loading the dataset function (+ augmentation) with the training part
    - I also added the ConintueTrainNetwork.py

****************************************************************
21OCT14
**************************************************************** 
+ Adaptive ROI selection applied. 
    - changed KNN background subtractor to MOG2 algorithm
    - learning rate for the back sub is modified according to the resemblance of the backsubed mask.
    - if the two following frames have similar backsubed mask, then the learning rate is lowered.
    - This operation is done by bitwize_and method
    => this resulted much better ROI selection 
+ ROI function applied.
    - I think this does not improve the result a lot, but I just added.
    - After constructing the ROI_image_stream, user manually select the ROI of the video stream.
    - Any image processed into the 
# TODO
    - [DONE] I don't know the exact algorithm of the MOG2. I setup the parameters with few trials and errors,
    but I should look into the original work to set the best parameters for my purpose.

****************************************************************
21OCT13
**************************************************************** 
# Problems
    * no adaptive ROI selection.
        => if background intensity changes in the middle of the video, ROI extractor totally lost.
        However, I have to use the whole video when I initially build the forground extractor.
        Becasue time to time the animal do not move during the initial seconds so animal fades out.
            => check the ROI position and apply adaptive learing rate according to the position difference?
    * Build manual label corrector.

****************************************************************
21NOV11
**************************************************************** 
# ReLabeler
    * ReLabeler is working great! Using the left hand keys (aswd) allows faster relabeling
    * Excursion detection feature seems to work well. 
# ROI detection method need to be upgraded
    * It works well in current state when applied to the Lobster Exp videos, but fails on Larget Exp videos. 
    * If the animal stays in a specific area for too long time, it definately fails. 
